{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a58c512",
   "metadata": {},
   "source": [
    "# Utiliser des LLM en API pour générer avec une prompt (zero shot)\n",
    "\n",
    "- des annotations : quels sont les articles qui mentionnent des thématiques IA\n",
    "- de l'extraction d'information : quelles sont les notions utilisées\n",
    "\n",
    "Quelques lectures \n",
    "\n",
    "- Stuhler, O., Ton, C. D., & Ollion, E. (2025). From Codebooks to Promptbooks: Extracting Information from Text with Generative Large Language Models. Sociological Methods & Research, 54(3), 794-848. https://doi.org/10.1177/00491241251336794 (Original work published 2025)\n",
    "- https://www.css.cnrs.fr/classification-with-generative-llms-and-api-calls/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c89c5",
   "metadata": {},
   "source": [
    "## Quelques mots sur le génératif\n",
    "\n",
    "- Prédiction du next token\n",
    "- Modèles pré-entrainés\n",
    "    - des tailles & alignements différents\n",
    "- Dépendances matérielles fortes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a593d6",
   "metadata": {},
   "source": [
    "## Quels modèles ?\n",
    "\n",
    "- vaste question\n",
    "- équilibre puissance/coût (financier et matériel)\n",
    "- enjeu de la sécurité des données\n",
    "\n",
    "De nombreux prestataires\n",
    "\n",
    "- openai, etc.\n",
    "- openrouter\n",
    "- humanum..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d8b96-bd38-4094-845b-1e3473464424",
   "metadata": {},
   "source": [
    "## Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bee33d6-78cd-4bcf-9e96-72ff45abaf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://openalex.org/W2159397589</td>\n",
       "      <td>Computational Social Science</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>A field is emerging that leverages the capacit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://openalex.org/W2070907364</td>\n",
       "      <td>Manifesto of computational social science</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://openalex.org/W3081158114</td>\n",
       "      <td>Computational social science: Obstacles and op...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Data sharing, research ethics, and incentives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://openalex.org/W3022499311</td>\n",
       "      <td>Computational Social Science and Sociology</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>The integration of social science with compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://openalex.org/W3174174150</td>\n",
       "      <td>Integrating explanation and prediction in comp...</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                id  \\\n",
       "0           0  https://openalex.org/W2159397589   \n",
       "1           1  https://openalex.org/W2070907364   \n",
       "2           2  https://openalex.org/W3081158114   \n",
       "3           3  https://openalex.org/W3022499311   \n",
       "4           4  https://openalex.org/W3174174150   \n",
       "\n",
       "                                               title  publication_year  \\\n",
       "0                       Computational Social Science            2009.0   \n",
       "1          Manifesto of computational social science            2012.0   \n",
       "2  Computational social science: Obstacles and op...            2020.0   \n",
       "3         Computational Social Science and Sociology            2020.0   \n",
       "4  Integrating explanation and prediction in comp...            2021.0   \n",
       "\n",
       "                                            abstract  \n",
       "0  A field is emerging that leverages the capacit...  \n",
       "1                                                NaN  \n",
       "2  Data sharing, research ethics, and incentives ...  \n",
       "3  The integration of social science with compute...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"../data/data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36267e89",
   "metadata": {},
   "source": [
    "## Charger une clé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f46b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "api_key = config[\"api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c9878",
   "metadata": {},
   "source": [
    "## Utiliser openrouter et l'API openapi\n",
    "\n",
    "Quickstart : https://platform.openai.com/docs/quickstart?api-mode=chat&language=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b32113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='gen-1770048186-aGVQuh1xRP0i75TZEps0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=None), native_finish_reason='stop')], created=1770048196, model='meta-llama/llama-3.3-70b-instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=25, prompt_tokens=19, total_tokens=44, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=None, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=None), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0), cost=1.668e-05, is_byok=False, cost_details={'upstream_inference_cost': 1.668e-05, 'upstream_inference_prompt_cost': 4.18e-06, 'upstream_inference_completions_cost': 1.25e-05}), provider='Parasail')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install openai\n",
    "from openai import OpenAI\n",
    "api_url = \"https://openrouter.ai/api/v1\"\n",
    " \n",
    "client = OpenAI(\n",
    "  base_url=api_url,\n",
    "  api_key=api_key,\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-3.3-70b-instruct\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, Llama. Say Hi!\"}]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32019b20",
   "metadata": {},
   "source": [
    "Choisir un modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4915b",
   "metadata": {},
   "source": [
    "Construire la prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "  {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are an efficient research assistant helping with text annotation.\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"\"\"\n",
    "    Annotate this following text if its topic is about AI or algorithms.\n",
    "    If so, returns AI, and otherwise, return NOT AI.\n",
    "    \"\"\"\n",
    "      + df[\"abstract\"].iloc[1]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01c4016a-8ede-4739-9524-7865a189890e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The topic of the text is about AI.\\n\\nThe returned value is: **AI**\\n\\nThe keywords associated with AI in the text are:\\n\\n* Machine learning (specifically, \"unsupervised learning\")\\n* Model-based clustering algorithms\\n* Mixture model\\n* Expectation Maximization algorithm\\n* Statistical inference\\n* Data distribution\\n* MNAR (Missing Not At Random) models\\n\\nThese keywords indicate that the text is related to artificial intelligence and machine learning, particularly in the context of handling missing data and developing algorithms for clustering and statistical analysis.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install openai\n",
    "from openai import OpenAI\n",
    "api_url = \"https://openrouter.ai/api/v1\"\n",
    " \n",
    "client = OpenAI(\n",
    "  base_url=api_url,\n",
    "  api_key=api_key,\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/llama-3.3-70b-instruct\",\n",
    "    messages=messages\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57b04c5",
   "metadata": {},
   "source": [
    "### Application Faire une boucle sur une liste de documents : évaluer si un abstract porte ou pas sur l'IA\n",
    "\n",
    "- Tester avec des exemples (few shot)\n",
    "- Tester avec du raisonnement (chaîne of thought)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a865bb9",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Comment évaluer la qualité d'un codage ? \n",
    "\n",
    "- La nécessité d'un gold standard\n",
    "- Le calcul de métriques `from sklearn.metrics import classification_report`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004633d3",
   "metadata": {},
   "source": [
    "### Application : construire un jeu de données d'évaluation\n",
    "\n",
    "- Utiliser des outils permettant l'interaction humaine\n",
    "- Toujours de l'ambiguité : accord inter-annotateur (alpha de Chronbach, autre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc3f4ce",
   "metadata": {},
   "source": [
    "### Mesurer la qualité d'une évaluation\n",
    "\n",
    "Différentes métriques\n",
    "\n",
    "- précision\n",
    "- recall\n",
    "- f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf95f72",
   "metadata": {},
   "source": [
    "## Application : extraire de l'information\n",
    "\n",
    "Sur les articles identifiés comme AI-related, extraire les termes liés pour les analyser\n",
    "\n",
    "- Construire une prompt\n",
    "- Tester sur plusieurs textes\n",
    "- Gérer la structure des données"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
